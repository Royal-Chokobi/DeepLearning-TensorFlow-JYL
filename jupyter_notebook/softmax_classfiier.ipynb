{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Softmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n[0.09003057 0.24472847 0.66524096]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "z = torch.FloatTensor([1, 2, 3])\n",
    "hypothesis = F.softmax(z, dim=0)\n",
    "\n",
    "print(hypothesis)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "x = np.array([1.0, 2.0, 3.0])\n",
    "y = softmax(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "plt.pie(y, labels=y)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0 5.3168488\n",
      "500 0.5216423\n",
      "1000 0.29899627\n",
      "1500 0.20769815\n",
      "2000 0.16978627\n--------------\n[[1.5235145e-01 8.4763914e-01 9.3735516e-06]] [1]\n--------------\n[[0.42844313 0.5145136  0.0570433 ]] [1]\n--------------\n[[1.8035951e-08 4.3145358e-04 9.9956852e-01]] [2]\n--------------\n[[1.5235154e-01 8.4763902e-01 9.3735507e-06]\n [4.2844296e-01 5.1451373e-01 5.7043299e-02]\n [1.8035951e-08 4.3145337e-04 9.9956852e-01]] [1 1 2]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.set_random_seed(777)\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.float32, [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "# Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "# print(\"one_hot:\", Y_one_hot)\n",
    "# Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
    "# print(\"reshape one_hot:\", Y_one_hot)\n",
    "'''\n",
    "one_hot: Tensor(\"one_hot:0\", shape=(?, 3, 3), dtype=float32)\n",
    "reshape one_hot: Tensor(\"Reshape:0\", shape=(?, 3), dtype=float32)\n",
    "'''\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "            _, cost_val = sess.run([optimizer, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(step, cost_val)\n",
    "\n",
    "    print('--------------')\n",
    "    # Testing & One-hot encoding\n",
    "    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\n",
    "    print(a, sess.run(tf.argmax(a, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4, 3]]})\n",
    "    print(b, sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0, 1]]})\n",
    "    print(c, sess.run(tf.argmax(c, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    all = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\n",
    "    print(all, sess.run(tf.argmax(all, 1)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}